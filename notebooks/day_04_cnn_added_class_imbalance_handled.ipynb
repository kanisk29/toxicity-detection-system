{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "import os\n",
        "\n",
        "# Create kaggle folder\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "# Move kaggle.json to the folder\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "\n",
        "# Set permissions (very important)\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
        "!unzip jigsaw-toxic-comment-classification-challenge.zip # unzipping the dataset's parent folder\n",
        "!unzip train.csv.zip #unzipping traning data\n",
        "!unzip test.csv.zip #unzipping test data and its labels\n",
        "!unzip test_labels.csv.zip\n",
        "!pip install gensim"
      ],
      "metadata": {
        "id": "fAbvdhonevC0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "84de37a3-46e9-4e90-dc65-6ad01dfd130e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ade28498-b2cb-4791-af2e-3d98e9444640\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ade28498-b2cb-4791-af2e-3d98e9444640\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading jigsaw-toxic-comment-classification-challenge.zip to /content\n",
            "  0% 0.00/52.6M [00:00<?, ?B/s]\n",
            "100% 52.6M/52.6M [00:00<00:00, 1.67GB/s]\n",
            "Archive:  jigsaw-toxic-comment-classification-challenge.zip\n",
            "  inflating: sample_submission.csv.zip  \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: test_labels.csv.zip     \n",
            "  inflating: train.csv.zip           \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  test_labels.csv.zip\n",
            "  inflating: test_labels.csv         \n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os                                   #imports\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import pandas as pd\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.metrics import Precision,Recall,CategoricalAccuracy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from tensorflow.keras.layers import Dropout,Dense,Embedding,LSTM,TextVectorization,Bidirectional,GRU,Convolution1D,GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "tCHBk4Id5DM3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"train.csv\") # reading the training dataset"
      ],
      "metadata": {
        "id": "rWW9Dwre4__M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sYrKA9BdDJGm",
        "outputId": "88021d98-732b-4666-a4e9-2db24f77bfac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
              "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
              "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
              "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
              "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
              "...                  ...                                                ...   \n",
              "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
              "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
              "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
              "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
              "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0           0             0        0       0       0              0  \n",
              "1           0             0        0       0       0              0  \n",
              "2           0             0        0       0       0              0  \n",
              "3           0             0        0       0       0              0  \n",
              "4           0             0        0       0       0              0  \n",
              "...       ...           ...      ...     ...     ...            ...  \n",
              "159566      0             0        0       0       0              0  \n",
              "159567      0             0        0       0       0              0  \n",
              "159568      0             0        0       0       0              0  \n",
              "159569      0             0        0       0       0              0  \n",
              "159570      0             0        0       0       0              0  \n",
              "\n",
              "[159571 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf4ba16a-9555-4bc4-b162-08a62aab68ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>ffe987279560d7ff</td>\n",
              "      <td>\":::::And for the second time of asking, when ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>ffea4adeee384e90</td>\n",
              "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>ffee36eab5c267c9</td>\n",
              "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>fff125370e4aaaf3</td>\n",
              "      <td>And it looks like it was actually you who put ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>fff46fc426af1f9a</td>\n",
              "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf4ba16a-9555-4bc4-b162-08a62aab68ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf4ba16a-9555-4bc4-b162-08a62aab68ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf4ba16a-9555-4bc4-b162-08a62aab68ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_843dbb11-df73-485a-844f-21ce471da2eb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_843dbb11-df73-485a-844f-21ce471da2eb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace = True)\n",
        "df.drop(\"id\",axis=1,inplace = True)"
      ],
      "metadata": {
        "id": "4eRj3v1K8Q9c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"comment_text\"]\n",
        "y = df.iloc[:,1:].values"
      ],
      "metadata": {
        "id": "QlFT7laJ5woH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_temp,y_train,y_temp = train_test_split(X,y,test_size = 0.3,random_state = 42)\n",
        "x_val,x_test,y_val,y_test = train_test_split(x_temp,y_temp,test_size = 0.4,random_state = 42)"
      ],
      "metadata": {
        "id": "a4sWpA9563cp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xku-Z6AC8HU9",
        "outputId": "90de3ffe-7754-4c90-d193-5f0703a23f26"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 100000 # this is the number of words in the vocab\n",
        "vectorizer = TextVectorization(max_tokens = max_features,\n",
        "                               output_sequence_length=200,\n",
        "                               output_mode = 'int')"
      ],
      "metadata": {
        "id": "y4V-8fNQ8Vjh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.adapt(x_train.values) # we are making the vectorizer learn the text"
      ],
      "metadata": {
        "id": "z_izaxXx82X7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_vectorized_text = vectorizer(x_train.values) #converting all the comments into vectors\n",
        "val_vectorized_text = vectorizer(x_val.values)\n",
        "test_vectorized_text = vectorizer(x_test.values)"
      ],
      "metadata": {
        "id": "EWHn7X7O9K8E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_vectorized_text,y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_vectorized_text,y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_vectorized_text,y_test))\n",
        "\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(len(x_train))\n",
        "train_dataset = train_dataset.batch(64)\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = val_dataset.batch(64)\n",
        "test_dataset = test_dataset.batch(64)\n",
        "\n",
        "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "YXvrnMxV9PK2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove = api.load(\"glove-wiki-gigaword-100\") #GloVe integration\n",
        "vocab = vectorizer.get_vocabulary()\n",
        "embedding_matrix = []\n",
        "embedding_dim = glove.vector_size\n",
        "embedding_matrix = np.zeros((len(vocab),embedding_dim))\n",
        "for idx,word in enumerate(vocab):\n",
        "  if word in glove:\n",
        "    embedding_matrix[idx] = glove[word]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQRuXDpFUV6q",
        "outputId": "c835eef6-f46a-49de-e5cb-83626c5ceb86"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hits = 0\n",
        "for word in vocab:\n",
        "    if word in glove:\n",
        "        hits += 1\n",
        "\n",
        "print(\"Coverage:\", hits / len(vocab))\n",
        "#as we can see the coverage is only 58% so we must keep the trainable parameter set to True during training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1MPeXgfVXlJ",
        "outputId": "a080cf2c-205f-45c2-8f1a-bb40e908da5b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage: 0.58313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_count = np.sum(y,axis=0)\n",
        "total_samples = y.shape[0]\n",
        "pos_weights = total_samples/(2*(label_count))\n",
        "print(\"Positive class weights per label:\")\n",
        "for label,weight in zip(df.columns[1:],pos_weights):\n",
        "  print(label,\":\",weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGiJ4yfNWodq",
        "outputId": "05b8ee28-b7d8-465c-b014-5640f87534b3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive class weights per label:\n",
            "toxic : 5.216784359879691\n",
            "severe_toxic : 50.02225705329153\n",
            "obscene : 9.443188543022844\n",
            "threat : 166.9152719665272\n",
            "insult : 10.128919639456646\n",
            "identity_hate : 56.78683274021353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_bce(pos_weights):\n",
        "  pos_weights_tensor = tf.constant(pos_weights,dtype = tf.float32)\n",
        "  def loss(y_true,y_pred):\n",
        "    eps = 1e-7\n",
        "    y_pred = tf.clip_by_value(y_pred,eps,1-eps) #for stable gradient\n",
        "    loss = -(pos_weights_tensor * y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
        "    return tf.reduce_mean(loss) #computes average loss of the 6 classes, this scalar is used for backprop\\\n",
        "  return loss"
      ],
      "metadata": {
        "id": "V15mpFRfWnJJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(layer = None,cnn = False):\n",
        "  tf.keras.backend.clear_session() # to clear gpu memory after each training\n",
        "  if cnn == False:\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim = len(vocab),output_dim = embedding_dim,weights = [embedding_matrix],mask_zero = True,trainable = True), #using pretrained vectors for better results\n",
        "        Bidirectional(layer(64)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(6, activation='sigmoid')\n",
        "    ])\n",
        "  else:\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim = len(vocab),output_dim = embedding_dim,weights = [embedding_matrix],trainable = True),\n",
        "        Convolution1D(kernel_size = 5,activation = 'relu',filters=64),\n",
        "        Dropout(0.2),\n",
        "        Convolution1D(kernel_size = 5,activation = 'relu',filters=128),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(6, activation='sigmoid')\n",
        "    ])\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss=weighted_bce(pos_weights),\n",
        "      metrics=[tf.keras.metrics.AUC(name = \"auc\",multi_label=True),\n",
        "                tf.keras.metrics.Precision(name = \"precision\",thresholds=0.3),\n",
        "                tf.keras.metrics.Recall(name = \"recall\",thresholds=0.3)]\n",
        "  )\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "OGIma_BjsPjK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = build_model(LSTM)\n",
        "model_gru  = build_model(GRU)\n",
        "cnn_model = build_model(cnn = True)"
      ],
      "metadata": {
        "id": "_YFOoXHctuUQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_auc\",\n",
        "        patience=2,\n",
        "        mode=\"max\",\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        \"best_model.keras\",\n",
        "        monitor=\"val_auc\",\n",
        "        mode=\"max\",\n",
        "        save_best_only=True\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "XZAYtOPZN-yW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "history_gru = model_gru.fit(train_dataset,epochs = 10, validation_data=val_dataset,callbacks = callbacks)\n",
        "print(\"Time taken for training by GRU:\", time.time() - start)"
      ],
      "metadata": {
        "id": "fboJzE0829PG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd319ed7-a2dc-432b-de18-83cef94edb98"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28ms/step - auc: 0.9243 - loss: 0.4410 - precision: 0.1737 - recall: 0.8947 - val_auc: 0.9804 - val_loss: 0.2619 - val_precision: 0.3204 - val_recall: 0.9319\n",
            "Epoch 2/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 28ms/step - auc: 0.9872 - loss: 0.1862 - precision: 0.3629 - recall: 0.9600 - val_auc: 0.9812 - val_loss: 0.2453 - val_precision: 0.3902 - val_recall: 0.9355\n",
            "Epoch 3/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 27ms/step - auc: 0.9918 - loss: 0.1256 - precision: 0.4648 - recall: 0.9793 - val_auc: 0.9686 - val_loss: 0.3888 - val_precision: 0.4907 - val_recall: 0.8945\n",
            "Epoch 4/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 27ms/step - auc: 0.9943 - loss: 0.0999 - precision: 0.5296 - recall: 0.9864 - val_auc: 0.9658 - val_loss: 0.4011 - val_precision: 0.4350 - val_recall: 0.9057\n",
            "Time taken for training by GRU: 201.87279748916626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "history_lstm = model_lstm.fit(train_dataset,epochs = 10, validation_data=val_dataset,callbacks = callbacks)\n",
        "print(\"Time taken for training by LSTM:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9kyYM5dWlIO",
        "outputId": "780ad0fa-6c2a-4262-e822-0e58beee417d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - auc: 0.9251 - loss: 0.4390 - precision: 0.1794 - recall: 0.8765 - val_auc: 0.9808 - val_loss: 0.2398 - val_precision: 0.2972 - val_recall: 0.9492\n",
            "Epoch 2/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 28ms/step - auc: 0.9861 - loss: 0.1902 - precision: 0.3540 - recall: 0.9619 - val_auc: 0.9790 - val_loss: 0.2481 - val_precision: 0.3457 - val_recall: 0.9355\n",
            "Epoch 3/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 28ms/step - auc: 0.9916 - loss: 0.1285 - precision: 0.4496 - recall: 0.9780 - val_auc: 0.9739 - val_loss: 0.3336 - val_precision: 0.4155 - val_recall: 0.9333\n",
            "Time taken for training by LSTM: 152.35443234443665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "history_cnn = cnn_model.fit(train_dataset,epochs = 10, validation_data=val_dataset,callbacks = callbacks)\n",
        "print(\"Time taken for training by CNN:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeNeNtz7Q3yd",
        "outputId": "6876623b-179f-4844-ff25-0b09331f8f4c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - auc: 0.9114 - loss: 0.4759 - precision: 0.1582 - recall: 0.8609 - val_auc: 0.9765 - val_loss: 0.2740 - val_precision: 0.2501 - val_recall: 0.9273\n",
            "Epoch 2/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - auc: 0.9801 - loss: 0.2337 - precision: 0.3073 - recall: 0.9457 - val_auc: 0.9774 - val_loss: 0.2575 - val_precision: 0.2925 - val_recall: 0.9547\n",
            "Epoch 3/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - auc: 0.9858 - loss: 0.1874 - precision: 0.3536 - recall: 0.9632 - val_auc: 0.9747 - val_loss: 0.2983 - val_precision: 0.1972 - val_recall: 0.9717\n",
            "Epoch 4/10\n",
            "\u001b[1m1746/1746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - auc: 0.9870 - loss: 0.1729 - precision: 0.3731 - recall: 0.9693 - val_auc: 0.9673 - val_loss: 0.3924 - val_precision: 0.4148 - val_recall: 0.9061\n",
            "Time taken for training by CNN: 69.81211161613464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Max AUC for GRU: {max(history_gru.history['val_auc'])}\")\n",
        "print(f\"Max AUC for LSTM: {max(history_lstm.history['val_auc'])}\")\n",
        "print(f\"Max AUC for CNN: {max(history_cnn.history['val_auc'])}\")"
      ],
      "metadata": {
        "id": "8gIybJCn3k0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6307d7-bf48-4f26-f981-79087bff9ba4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max AUC for GRU: 0.9811680912971497\n",
            "Max AUC for LSTM: 0.9808200001716614\n",
            "Max AUC for CNN: 0.9773985743522644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Max Precision for GRU: {max(history_gru.history['val_precision'])}\")\n",
        "print(f\"Max Precision for LSTM: {max(history_lstm.history['val_precision'])}\")\n",
        "print(f\"Max Precision for CNN: {max(history_cnn.history['val_precision'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4zpTtwMXU9A",
        "outputId": "dea09b7a-b060-4dbb-b704-2a01794d3b31"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Precision for GRU: 0.4906778037548065\n",
            "Max Precision for LSTM: 0.4154999256134033\n",
            "Max Precision for CNN: 0.4147884249687195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Max Recall for GRU: {max(history_gru.history['val_recall'])}\")\n",
        "print(f\"Max Recall for LSTM: {max(history_lstm.history['val_recall'])}\")\n",
        "print(f\"Max Recall for CNN: {max(history_cnn.history['val_recall'])}\")"
      ],
      "metadata": {
        "id": "j8RNq8_MOnE2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56488704-c475-44e7-917d-0a13d0c98c6e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Recall for GRU: 0.9355146288871765\n",
            "Max Recall for LSTM: 0.9491741061210632\n",
            "Max Recall for CNN: 0.9717280864715576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictor(ip_text,model_name):\n",
        "  pred = model_name(vectorizer([ip_text]),training = False).numpy()\n",
        "  labels = [\"toxic\",'severe_toxic',\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
        "  threshold = 0.3\n",
        "  pred_labels = (pred > threshold).astype(int)\n",
        "  flagged = False\n",
        "  print(\"This comment is: \")\n",
        "  for i in range(len(labels)):\n",
        "    if pred_labels[0][i] == 1:\n",
        "      print(labels[i])\n",
        "      flagged = True\n",
        "  if flagged == False:\n",
        "    print(\"safe\")"
      ],
      "metadata": {
        "id": "uZFgNOEiC6S0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def macro_f1(model_name):\n",
        "  all_preds = []\n",
        "  all_true = []\n",
        "  for x_batch,y_batch in test_dataset:\n",
        "    preds = model_name(x_batch,training = False).numpy()\n",
        "    all_preds.append(preds)\n",
        "    all_true.append(y_batch.numpy())\n",
        "  all_preds = np.vstack(all_preds)\n",
        "  all_true = np.vstack(all_true)\n",
        "  preds_binary = (all_preds>0.3).astype(int)\n",
        "  return f\"Macro F1 of {model_name}: {f1_score(all_true,preds_binary,average = 'macro')}\""
      ],
      "metadata": {
        "id": "i8_GMO4MXi8D"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(macro_f1(model_lstm))\n",
        "print(macro_f1(model_gru))\n",
        "print(macro_f1(cnn_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GREpYBoUY0JR",
        "outputId": "1b450699-0d81-4b31-d87f-f697aa464c4e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro F1 of <Sequential name=sequential, built=True>: 0.36947522358502755\n",
            "Macro F1 of <Sequential name=sequential, built=True>: 0.43937298234365413\n",
            "Macro F1 of <Sequential name=sequential, built=True>: 0.3596000148860969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_comment(comment,model_name):\n",
        "  flagged = False\n",
        "  input_str = vectorizer([comment])\n",
        "  res = model_name(input_str,training = False).numpy()\n",
        "  text = ' '\n",
        "  for idx,cols in enumerate(df.columns[1:]):\n",
        "    is_toxic = res[0][idx] > 0.3\n",
        "    text += '{}: {}  '.format(cols,is_toxic)\n",
        "    if is_toxic:\n",
        "      flagged = True\n",
        "  if flagged == False:\n",
        "    print(\"\\n\\n\\n Safe\")\n",
        "  return text"
      ],
      "metadata": {
        "id": "cnuUYaAPMEJG"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}